{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Cancer_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbimosl/CiDvsDWVa0b3mL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmorgancooper/Cancer_Classification/blob/master/NN_Cancer_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10c7fsEpisAn",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network to predict whether a tumour is malign.\n",
        "Data from UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. Copy found: https://goo.gl/U2Uwz2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rURAr2cZgXme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c04bccd8-1344-491d-ec41-22715ebf704f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztnQ4_j9jKVw",
        "colab_type": "text"
      },
      "source": [
        "#Load and explore file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqbBv-60gntl",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "0e16ab32-6c3d-4abd-902e-0c852fd21ae9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f4c6d7b-5c6a-46b2-8104-56ca7c734c53\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0f4c6d7b-5c6a-46b2-8104-56ca7c734c53\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cancer_classification.csv to cancer_classification.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NRYjfYYg7d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['cancer_classification.csv']))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0ceeonShPTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "002a57ca-8654-4550-b014-7a6a9ac361c2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>benign_0__mal_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  benign_0__mal_1\n",
              "0        17.99         10.38  ...                  0.11890                0\n",
              "1        20.57         17.77  ...                  0.08902                0\n",
              "2        19.69         21.25  ...                  0.08758                0\n",
              "3        11.42         20.38  ...                  0.17300                0\n",
              "4        20.29         14.34  ...                  0.07678                0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6fstvSsiYaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "80203f9b-f013-4169-e784-a368dab06ae5"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  benign_0__mal_1          569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xza1xvQsibIh",
        "colab_type": "text"
      },
      "source": [
        "No null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GJoR5gCidE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f2db615-0510-4445-a657-1b6b3c2ad64b"
      },
      "source": [
        "df.duplicated().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPepWH1zig2G",
        "colab_type": "text"
      },
      "source": [
        "No duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BHPHu1Tiij9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "cf3e789d-a6ba-4103-f3b9-939a61a12c85"
      },
      "source": [
        "df.describe().transpose()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean radius</th>\n",
              "      <td>569.0</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>28.11000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean texture</th>\n",
              "      <td>569.0</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>39.28000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean perimeter</th>\n",
              "      <td>569.0</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>188.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean area</th>\n",
              "      <td>569.0</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>2501.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean smoothness</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.16340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean compactness</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.34540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concavity</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.42680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concave points</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.20120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean symmetry</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.30400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.09744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>2.87300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>4.88500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>21.98000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>542.20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.03113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.13540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.39600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.05279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.07895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal dimension error</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>0.02984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst radius</th>\n",
              "      <td>569.0</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>36.04000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst texture</th>\n",
              "      <td>569.0</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>49.54000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst perimeter</th>\n",
              "      <td>569.0</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>251.20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst area</th>\n",
              "      <td>569.0</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>4254.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst smoothness</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.22260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst compactness</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>1.05800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst concavity</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>1.25200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst concave points</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.29100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst symmetry</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.66380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>0.20750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>benign_0__mal_1</th>\n",
              "      <td>569.0</td>\n",
              "      <td>0.627417</td>\n",
              "      <td>0.483918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         count        mean  ...          75%         max\n",
              "mean radius              569.0   14.127292  ...    15.780000    28.11000\n",
              "mean texture             569.0   19.289649  ...    21.800000    39.28000\n",
              "mean perimeter           569.0   91.969033  ...   104.100000   188.50000\n",
              "mean area                569.0  654.889104  ...   782.700000  2501.00000\n",
              "mean smoothness          569.0    0.096360  ...     0.105300     0.16340\n",
              "mean compactness         569.0    0.104341  ...     0.130400     0.34540\n",
              "mean concavity           569.0    0.088799  ...     0.130700     0.42680\n",
              "mean concave points      569.0    0.048919  ...     0.074000     0.20120\n",
              "mean symmetry            569.0    0.181162  ...     0.195700     0.30400\n",
              "mean fractal dimension   569.0    0.062798  ...     0.066120     0.09744\n",
              "radius error             569.0    0.405172  ...     0.478900     2.87300\n",
              "texture error            569.0    1.216853  ...     1.474000     4.88500\n",
              "perimeter error          569.0    2.866059  ...     3.357000    21.98000\n",
              "area error               569.0   40.337079  ...    45.190000   542.20000\n",
              "smoothness error         569.0    0.007041  ...     0.008146     0.03113\n",
              "compactness error        569.0    0.025478  ...     0.032450     0.13540\n",
              "concavity error          569.0    0.031894  ...     0.042050     0.39600\n",
              "concave points error     569.0    0.011796  ...     0.014710     0.05279\n",
              "symmetry error           569.0    0.020542  ...     0.023480     0.07895\n",
              "fractal dimension error  569.0    0.003795  ...     0.004558     0.02984\n",
              "worst radius             569.0   16.269190  ...    18.790000    36.04000\n",
              "worst texture            569.0   25.677223  ...    29.720000    49.54000\n",
              "worst perimeter          569.0  107.261213  ...   125.400000   251.20000\n",
              "worst area               569.0  880.583128  ...  1084.000000  4254.00000\n",
              "worst smoothness         569.0    0.132369  ...     0.146000     0.22260\n",
              "worst compactness        569.0    0.254265  ...     0.339100     1.05800\n",
              "worst concavity          569.0    0.272188  ...     0.382900     1.25200\n",
              "worst concave points     569.0    0.114606  ...     0.161400     0.29100\n",
              "worst symmetry           569.0    0.290076  ...     0.317900     0.66380\n",
              "worst fractal dimension  569.0    0.083946  ...     0.092080     0.20750\n",
              "benign_0__mal_1          569.0    0.627417  ...     1.000000     1.00000\n",
              "\n",
              "[31 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IDAewQdiqla",
        "colab_type": "text"
      },
      "source": [
        "Checking if data is balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OJ6s7gXjxPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "24bca444-49ad-4220-f73e-b7d4b042a4a7"
      },
      "source": [
        "df['benign_0__mal_1'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: benign_0__mal_1, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjt4orHFj3To",
        "colab_type": "text"
      },
      "source": [
        "More malignant than benign but fairly well balanced.\n",
        "Next checking correlation of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEXbCWFmj1uZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "cdca2612-7084-4072-cf55-b84ab8385a22"
      },
      "source": [
        "abs(df.corr()['benign_0__mal_1']).sort_values(ascending = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "benign_0__mal_1            1.000000\n",
              "worst concave points       0.793566\n",
              "worst perimeter            0.782914\n",
              "mean concave points        0.776614\n",
              "worst radius               0.776454\n",
              "mean perimeter             0.742636\n",
              "worst area                 0.733825\n",
              "mean radius                0.730029\n",
              "mean area                  0.708984\n",
              "mean concavity             0.696360\n",
              "worst concavity            0.659610\n",
              "mean compactness           0.596534\n",
              "worst compactness          0.590998\n",
              "radius error               0.567134\n",
              "perimeter error            0.556141\n",
              "area error                 0.548236\n",
              "worst texture              0.456903\n",
              "worst smoothness           0.421465\n",
              "worst symmetry             0.416294\n",
              "mean texture               0.415185\n",
              "concave points error       0.408042\n",
              "mean smoothness            0.358560\n",
              "mean symmetry              0.330499\n",
              "worst fractal dimension    0.323872\n",
              "compactness error          0.292999\n",
              "concavity error            0.253730\n",
              "fractal dimension error    0.077972\n",
              "smoothness error           0.067016\n",
              "mean fractal dimension     0.012838\n",
              "texture error              0.008303\n",
              "symmetry error             0.006522\n",
              "Name: benign_0__mal_1, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP_ALv5xkYM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzqDzWtxlGfp",
        "colab_type": "text"
      },
      "source": [
        "Many of the features have strong correlation with the target column so should be able to get decent predictions from the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQs_E_ncmc-K",
        "colab_type": "text"
      },
      "source": [
        "# Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0QXSTl_lsAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av5ODjlZlweH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop('benign_0__mal_1', axis = 1).values\n",
        "y = df['benign_0__mal_1'].values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avPJznT2l5bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMPeSbgZmInv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO17WZRUmhus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tevdLDqJmmcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4e7a292c-9083-4e3f-e136-0041870f20eb"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.301e+01, 2.222e+01, 8.201e+01, ..., 9.259e-03, 2.295e-01,\n",
              "        5.843e-02],\n",
              "       [1.469e+01, 1.398e+01, 9.822e+01, ..., 1.108e-01, 2.827e-01,\n",
              "        9.208e-02],\n",
              "       [1.471e+01, 2.159e+01, 9.555e+01, ..., 1.834e-01, 3.698e-01,\n",
              "        1.094e-01],\n",
              "       ...,\n",
              "       [1.607e+01, 1.965e+01, 1.041e+02, ..., 1.520e-01, 2.650e-01,\n",
              "        6.387e-02],\n",
              "       [1.877e+01, 2.143e+01, 1.229e+02, ..., 2.048e-01, 3.679e-01,\n",
              "        9.870e-02],\n",
              "       [1.371e+01, 1.868e+01, 8.873e+01, ..., 1.284e-01, 2.849e-01,\n",
              "        9.031e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJCBAU1kmjB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = scaler.fit_transform(X_train)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88sAQ264mpIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "719a1b3c-6300-4da4-f362-b313a2ac1220"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29497529, 0.42306392, 0.26706729, ..., 0.03181787, 0.14373028,\n",
              "        0.02114387],\n",
              "       [0.37717109, 0.14440311, 0.3803368 , ..., 0.38075601, 0.24861987,\n",
              "        0.24210388],\n",
              "       [0.37814962, 0.40175854, 0.36167983, ..., 0.63024055, 0.420347  ,\n",
              "        0.35583426],\n",
              "       ...,\n",
              "       [0.44468907, 0.3361515 , 0.42142408, ..., 0.52233677, 0.2137224 ,\n",
              "        0.05686519],\n",
              "       [0.57678947, 0.39634765, 0.55279156, ..., 0.70378007, 0.41660095,\n",
              "        0.28557358],\n",
              "       [0.32922354, 0.30334799, 0.31402418, ..., 0.44123711, 0.25295741,\n",
              "        0.23048132]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz9GG4mNmww0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivJCmUkJm0rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ynY_MIAoYE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2a4a25f-f4a6-4b95-e5a9-c389bea885c6"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(398, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3OqTScxoeUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "#Binary classification so use sigmoid fn and binary_crossentropy\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW6EmRn9pA78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38be05fa-9a0a-4d7e-c0fe-1e4da5bf3c45"
      },
      "source": [
        "model.fit(x = X_train, y = y_train, epochs = 600, validation_data=(X_test, y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.6650 - val_loss: 0.6461\n",
            "Epoch 2/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 0.6089\n",
            "Epoch 3/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5826 - val_loss: 0.5690\n",
            "Epoch 4/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5385 - val_loss: 0.5255\n",
            "Epoch 5/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4938 - val_loss: 0.4797\n",
            "Epoch 6/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4447 - val_loss: 0.4350\n",
            "Epoch 7/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3994 - val_loss: 0.3915\n",
            "Epoch 8/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3580 - val_loss: 0.3525\n",
            "Epoch 9/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3222 - val_loss: 0.3217\n",
            "Epoch 10/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2927 - val_loss: 0.2936\n",
            "Epoch 11/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2684 - val_loss: 0.2712\n",
            "Epoch 12/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2457 - val_loss: 0.2537\n",
            "Epoch 13/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2279 - val_loss: 0.2378\n",
            "Epoch 14/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2110 - val_loss: 0.2245\n",
            "Epoch 15/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1981 - val_loss: 0.2133\n",
            "Epoch 16/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1846 - val_loss: 0.2033\n",
            "Epoch 17/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1751 - val_loss: 0.1948\n",
            "Epoch 18/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1666 - val_loss: 0.1888\n",
            "Epoch 19/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1573 - val_loss: 0.1819\n",
            "Epoch 20/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1766\n",
            "Epoch 21/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1421 - val_loss: 0.1715\n",
            "Epoch 22/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1669\n",
            "Epoch 23/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1358 - val_loss: 0.1632\n",
            "Epoch 24/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.1608\n",
            "Epoch 25/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1208 - val_loss: 0.1566\n",
            "Epoch 26/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1161 - val_loss: 0.1549\n",
            "Epoch 27/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.1510\n",
            "Epoch 28/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1064 - val_loss: 0.1483\n",
            "Epoch 29/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1060 - val_loss: 0.1479\n",
            "Epoch 30/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0995 - val_loss: 0.1450\n",
            "Epoch 31/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.1432\n",
            "Epoch 32/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0928 - val_loss: 0.1420\n",
            "Epoch 33/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.1390\n",
            "Epoch 34/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.1385\n",
            "Epoch 35/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.1377\n",
            "Epoch 36/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0842 - val_loss: 0.1358\n",
            "Epoch 37/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.1351\n",
            "Epoch 38/600\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0778 - val_loss: 0.1338\n",
            "Epoch 39/600\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0766 - val_loss: 0.1334\n",
            "Epoch 40/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.1325\n",
            "Epoch 41/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.1322\n",
            "Epoch 42/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.1307\n",
            "Epoch 43/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.1306\n",
            "Epoch 44/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.1300\n",
            "Epoch 45/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.1298\n",
            "Epoch 46/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.1287\n",
            "Epoch 47/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 0.1307\n",
            "Epoch 48/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.1293\n",
            "Epoch 49/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.1281\n",
            "Epoch 50/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.1278\n",
            "Epoch 51/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.1275\n",
            "Epoch 52/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.1275\n",
            "Epoch 53/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.1271\n",
            "Epoch 54/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.1279\n",
            "Epoch 55/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.1278\n",
            "Epoch 56/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.1276\n",
            "Epoch 57/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.1283\n",
            "Epoch 58/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.1281\n",
            "Epoch 59/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.1269\n",
            "Epoch 60/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.1305\n",
            "Epoch 61/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.1262\n",
            "Epoch 62/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.1274\n",
            "Epoch 63/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.1294\n",
            "Epoch 64/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.1273\n",
            "Epoch 65/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.1280\n",
            "Epoch 66/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.1273\n",
            "Epoch 67/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.1277\n",
            "Epoch 68/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.1275\n",
            "Epoch 69/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.1279\n",
            "Epoch 70/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.1277\n",
            "Epoch 71/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.1280\n",
            "Epoch 72/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.1284\n",
            "Epoch 73/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.1282\n",
            "Epoch 74/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.1292\n",
            "Epoch 75/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.1286\n",
            "Epoch 76/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.1283\n",
            "Epoch 77/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.1298\n",
            "Epoch 78/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.1276\n",
            "Epoch 79/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.1294\n",
            "Epoch 80/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.1298\n",
            "Epoch 81/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.1300\n",
            "Epoch 82/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.1312\n",
            "Epoch 83/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.1297\n",
            "Epoch 84/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.1320\n",
            "Epoch 85/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.1302\n",
            "Epoch 86/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.1303\n",
            "Epoch 87/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.1312\n",
            "Epoch 88/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.1325\n",
            "Epoch 89/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.1306\n",
            "Epoch 90/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.1313\n",
            "Epoch 91/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.1336\n",
            "Epoch 92/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.1311\n",
            "Epoch 93/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.1329\n",
            "Epoch 94/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.1335\n",
            "Epoch 95/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.1312\n",
            "Epoch 96/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.1317\n",
            "Epoch 97/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.1355\n",
            "Epoch 98/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.1329\n",
            "Epoch 99/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.1373\n",
            "Epoch 100/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.1344\n",
            "Epoch 101/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.1351\n",
            "Epoch 102/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.1340\n",
            "Epoch 103/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.1337\n",
            "Epoch 104/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.1335\n",
            "Epoch 105/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.1372\n",
            "Epoch 106/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.1343\n",
            "Epoch 107/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.1371\n",
            "Epoch 108/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.1361\n",
            "Epoch 109/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.1366\n",
            "Epoch 110/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.1350\n",
            "Epoch 111/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.1370\n",
            "Epoch 112/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.1371\n",
            "Epoch 113/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.1372\n",
            "Epoch 114/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.1410\n",
            "Epoch 115/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.1372\n",
            "Epoch 116/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.1404\n",
            "Epoch 117/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.1374\n",
            "Epoch 118/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.1391\n",
            "Epoch 119/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.1456\n",
            "Epoch 120/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.1370\n",
            "Epoch 121/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.1430\n",
            "Epoch 122/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.1372\n",
            "Epoch 123/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.1450\n",
            "Epoch 124/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.1375\n",
            "Epoch 125/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.1371\n",
            "Epoch 126/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.1393\n",
            "Epoch 127/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.1362\n",
            "Epoch 128/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.1399\n",
            "Epoch 129/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.1365\n",
            "Epoch 130/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.1395\n",
            "Epoch 131/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.1408\n",
            "Epoch 132/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.1406\n",
            "Epoch 133/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.1385\n",
            "Epoch 134/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.1419\n",
            "Epoch 135/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.1401\n",
            "Epoch 136/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.1408\n",
            "Epoch 137/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.1411\n",
            "Epoch 138/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.1420\n",
            "Epoch 139/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.1402\n",
            "Epoch 140/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.1441\n",
            "Epoch 141/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.1397\n",
            "Epoch 142/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.1476\n",
            "Epoch 143/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.1399\n",
            "Epoch 144/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.1488\n",
            "Epoch 145/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.1425\n",
            "Epoch 146/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.1414\n",
            "Epoch 147/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.1425\n",
            "Epoch 148/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.1395\n",
            "Epoch 149/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.1430\n",
            "Epoch 150/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.1430\n",
            "Epoch 151/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.1412\n",
            "Epoch 152/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.1447\n",
            "Epoch 153/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.1430\n",
            "Epoch 154/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.1465\n",
            "Epoch 155/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.1447\n",
            "Epoch 156/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.1424\n",
            "Epoch 157/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.1450\n",
            "Epoch 158/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.1422\n",
            "Epoch 159/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.1500\n",
            "Epoch 160/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.1432\n",
            "Epoch 161/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.1440\n",
            "Epoch 162/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.1464\n",
            "Epoch 163/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.1447\n",
            "Epoch 164/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.1469\n",
            "Epoch 165/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.1436\n",
            "Epoch 166/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.1465\n",
            "Epoch 167/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.1435\n",
            "Epoch 168/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.1493\n",
            "Epoch 169/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.1435\n",
            "Epoch 170/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.1501\n",
            "Epoch 171/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.1477\n",
            "Epoch 172/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.1431\n",
            "Epoch 173/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.1463\n",
            "Epoch 174/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.1464\n",
            "Epoch 175/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.1484\n",
            "Epoch 176/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.1480\n",
            "Epoch 177/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.1493\n",
            "Epoch 178/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.1459\n",
            "Epoch 179/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.1476\n",
            "Epoch 180/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.1462\n",
            "Epoch 181/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.1470\n",
            "Epoch 182/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.1497\n",
            "Epoch 183/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - val_loss: 0.1466\n",
            "Epoch 184/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.1487\n",
            "Epoch 185/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.1554\n",
            "Epoch 186/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.1467\n",
            "Epoch 187/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.1526\n",
            "Epoch 188/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.1450\n",
            "Epoch 189/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.1490\n",
            "Epoch 190/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.1485\n",
            "Epoch 191/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.1484\n",
            "Epoch 192/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.1661\n",
            "Epoch 193/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.1485\n",
            "Epoch 194/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.1524\n",
            "Epoch 195/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.1479\n",
            "Epoch 196/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.1542\n",
            "Epoch 197/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.1497\n",
            "Epoch 198/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.1497\n",
            "Epoch 199/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.1527\n",
            "Epoch 200/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.1503\n",
            "Epoch 201/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.1506\n",
            "Epoch 202/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.1528\n",
            "Epoch 203/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.1510\n",
            "Epoch 204/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.1513\n",
            "Epoch 205/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.1517\n",
            "Epoch 206/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.1508\n",
            "Epoch 207/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.1493\n",
            "Epoch 208/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.1513\n",
            "Epoch 209/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.1519\n",
            "Epoch 210/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.1537\n",
            "Epoch 211/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.1535\n",
            "Epoch 212/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.1532\n",
            "Epoch 213/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.1535\n",
            "Epoch 214/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.1562\n",
            "Epoch 215/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.1518\n",
            "Epoch 216/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.1546\n",
            "Epoch 217/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.1530\n",
            "Epoch 218/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.1567\n",
            "Epoch 219/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.1533\n",
            "Epoch 220/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.1557\n",
            "Epoch 221/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.1536\n",
            "Epoch 222/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.1533\n",
            "Epoch 223/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.1577\n",
            "Epoch 224/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.1538\n",
            "Epoch 225/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.1570\n",
            "Epoch 226/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.1594\n",
            "Epoch 227/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.1607\n",
            "Epoch 228/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.1586\n",
            "Epoch 229/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.1591\n",
            "Epoch 230/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.1545\n",
            "Epoch 231/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.1569\n",
            "Epoch 232/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.1571\n",
            "Epoch 233/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.1588\n",
            "Epoch 234/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.1650\n",
            "Epoch 235/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.1616\n",
            "Epoch 236/600\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.1631\n",
            "Epoch 237/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.1655\n",
            "Epoch 238/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.1556\n",
            "Epoch 239/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.1578\n",
            "Epoch 240/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.1558\n",
            "Epoch 241/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.1547\n",
            "Epoch 242/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.1615\n",
            "Epoch 243/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.1606\n",
            "Epoch 244/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.1564\n",
            "Epoch 245/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.1595\n",
            "Epoch 246/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.1659\n",
            "Epoch 247/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.1586\n",
            "Epoch 248/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.1591\n",
            "Epoch 249/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.1646\n",
            "Epoch 250/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.1598\n",
            "Epoch 251/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.1574\n",
            "Epoch 252/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.1582\n",
            "Epoch 253/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.1582\n",
            "Epoch 254/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.1573\n",
            "Epoch 255/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.1558\n",
            "Epoch 256/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.1548\n",
            "Epoch 257/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.1563\n",
            "Epoch 258/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.1589\n",
            "Epoch 259/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.1605\n",
            "Epoch 260/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.1574\n",
            "Epoch 261/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.1643\n",
            "Epoch 262/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.1571\n",
            "Epoch 263/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.1720\n",
            "Epoch 264/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.1585\n",
            "Epoch 265/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.1645\n",
            "Epoch 266/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.1600\n",
            "Epoch 267/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.1628\n",
            "Epoch 268/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.1645\n",
            "Epoch 269/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.1578\n",
            "Epoch 270/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.1710\n",
            "Epoch 271/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.1591\n",
            "Epoch 272/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.1626\n",
            "Epoch 273/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.1590\n",
            "Epoch 274/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.1631\n",
            "Epoch 275/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.1596\n",
            "Epoch 276/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.1639\n",
            "Epoch 277/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.1609\n",
            "Epoch 278/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.1642\n",
            "Epoch 279/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.1626\n",
            "Epoch 280/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.1593\n",
            "Epoch 281/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.1605\n",
            "Epoch 282/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.1657\n",
            "Epoch 283/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.1565\n",
            "Epoch 284/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.1715\n",
            "Epoch 285/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.1561\n",
            "Epoch 286/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.1587\n",
            "Epoch 287/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.1583\n",
            "Epoch 288/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.1569\n",
            "Epoch 289/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.1621\n",
            "Epoch 290/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.1625\n",
            "Epoch 291/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.1582\n",
            "Epoch 292/600\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.1659\n",
            "Epoch 293/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.1604\n",
            "Epoch 294/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.1691\n",
            "Epoch 295/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.1617\n",
            "Epoch 296/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.1612\n",
            "Epoch 297/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.1633\n",
            "Epoch 298/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.1616\n",
            "Epoch 299/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.1606\n",
            "Epoch 300/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.1588\n",
            "Epoch 301/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.1558\n",
            "Epoch 302/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.1579\n",
            "Epoch 303/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.1625\n",
            "Epoch 304/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.1596\n",
            "Epoch 305/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.1609\n",
            "Epoch 306/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.1609\n",
            "Epoch 307/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.1628\n",
            "Epoch 308/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.1669\n",
            "Epoch 309/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.1622\n",
            "Epoch 310/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.1676\n",
            "Epoch 311/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.1612\n",
            "Epoch 312/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.1696\n",
            "Epoch 313/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.1627\n",
            "Epoch 314/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.1704\n",
            "Epoch 315/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.1612\n",
            "Epoch 316/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.1619\n",
            "Epoch 317/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.1599\n",
            "Epoch 318/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.1651\n",
            "Epoch 319/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.1611\n",
            "Epoch 320/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.1699\n",
            "Epoch 321/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.1630\n",
            "Epoch 322/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.1630\n",
            "Epoch 323/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.1668\n",
            "Epoch 324/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.1690\n",
            "Epoch 325/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.1643\n",
            "Epoch 326/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.1678\n",
            "Epoch 327/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.1672\n",
            "Epoch 328/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.1671\n",
            "Epoch 329/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.1722\n",
            "Epoch 330/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.1640\n",
            "Epoch 331/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.1733\n",
            "Epoch 332/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.1644\n",
            "Epoch 333/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.1707\n",
            "Epoch 334/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.1710\n",
            "Epoch 335/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.1725\n",
            "Epoch 336/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.1726\n",
            "Epoch 337/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.1711\n",
            "Epoch 338/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.1746\n",
            "Epoch 339/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.1694\n",
            "Epoch 340/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.1802\n",
            "Epoch 341/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.1722\n",
            "Epoch 342/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.1655\n",
            "Epoch 343/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.1687\n",
            "Epoch 344/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.1676\n",
            "Epoch 345/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.1718\n",
            "Epoch 346/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.1695\n",
            "Epoch 347/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.1672\n",
            "Epoch 348/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.1760\n",
            "Epoch 349/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.1666\n",
            "Epoch 350/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.1731\n",
            "Epoch 351/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.1720\n",
            "Epoch 352/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.1741\n",
            "Epoch 353/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.1781\n",
            "Epoch 354/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.1787\n",
            "Epoch 355/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.1791\n",
            "Epoch 356/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.1772\n",
            "Epoch 357/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.1821\n",
            "Epoch 358/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.1793\n",
            "Epoch 359/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.1793\n",
            "Epoch 360/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.1765\n",
            "Epoch 361/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.1798\n",
            "Epoch 362/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.1782\n",
            "Epoch 363/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.1784\n",
            "Epoch 364/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.1753\n",
            "Epoch 365/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.1716\n",
            "Epoch 366/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.1731\n",
            "Epoch 367/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.1728\n",
            "Epoch 368/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.1772\n",
            "Epoch 369/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.1780\n",
            "Epoch 370/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.1755\n",
            "Epoch 371/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.1769\n",
            "Epoch 372/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.1820\n",
            "Epoch 373/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.1811\n",
            "Epoch 374/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.1822\n",
            "Epoch 375/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.1813\n",
            "Epoch 376/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.1840\n",
            "Epoch 377/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.1854\n",
            "Epoch 378/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.1894\n",
            "Epoch 379/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.1938\n",
            "Epoch 380/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.1859\n",
            "Epoch 381/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.1858\n",
            "Epoch 382/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.1877\n",
            "Epoch 383/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.1952\n",
            "Epoch 384/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.1897\n",
            "Epoch 385/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.1895\n",
            "Epoch 386/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.1855\n",
            "Epoch 387/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.1885\n",
            "Epoch 388/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.1868\n",
            "Epoch 389/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.1889\n",
            "Epoch 390/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.1957\n",
            "Epoch 391/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.1914\n",
            "Epoch 392/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.1930\n",
            "Epoch 393/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.1947\n",
            "Epoch 394/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.1994\n",
            "Epoch 395/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.1997\n",
            "Epoch 396/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.1970\n",
            "Epoch 397/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.1931\n",
            "Epoch 398/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.1979\n",
            "Epoch 399/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.1961\n",
            "Epoch 400/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.1891\n",
            "Epoch 401/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.1897\n",
            "Epoch 402/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.1948\n",
            "Epoch 403/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.1986\n",
            "Epoch 404/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.1967\n",
            "Epoch 405/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.1956\n",
            "Epoch 406/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.2057\n",
            "Epoch 407/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.2035\n",
            "Epoch 408/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.1964\n",
            "Epoch 409/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.1965\n",
            "Epoch 410/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.1983\n",
            "Epoch 411/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.2020\n",
            "Epoch 412/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.2021\n",
            "Epoch 413/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.2037\n",
            "Epoch 414/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.1969\n",
            "Epoch 415/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.1966\n",
            "Epoch 416/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.2016\n",
            "Epoch 417/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.2037\n",
            "Epoch 418/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.2049\n",
            "Epoch 419/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.2099\n",
            "Epoch 420/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.2086\n",
            "Epoch 421/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.2048\n",
            "Epoch 422/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.2061\n",
            "Epoch 423/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.2080\n",
            "Epoch 424/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.2105\n",
            "Epoch 425/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.2097\n",
            "Epoch 426/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.2165\n",
            "Epoch 427/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.2201\n",
            "Epoch 428/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.2112\n",
            "Epoch 429/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.2063\n",
            "Epoch 430/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.2104\n",
            "Epoch 431/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.2120\n",
            "Epoch 432/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.2135\n",
            "Epoch 433/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.2116\n",
            "Epoch 434/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.2128\n",
            "Epoch 435/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.2126\n",
            "Epoch 436/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.2155\n",
            "Epoch 437/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.2151\n",
            "Epoch 438/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.2190\n",
            "Epoch 439/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.2172\n",
            "Epoch 440/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.2184\n",
            "Epoch 441/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.2212\n",
            "Epoch 442/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.2193\n",
            "Epoch 443/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.2191\n",
            "Epoch 444/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.2187\n",
            "Epoch 445/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.2222\n",
            "Epoch 446/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.2228\n",
            "Epoch 447/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.2303\n",
            "Epoch 448/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.2335\n",
            "Epoch 449/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.2309\n",
            "Epoch 450/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.2236\n",
            "Epoch 451/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.2275\n",
            "Epoch 452/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.2353\n",
            "Epoch 453/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.2333\n",
            "Epoch 454/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.2330\n",
            "Epoch 455/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.2346\n",
            "Epoch 456/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.2323\n",
            "Epoch 457/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.2317\n",
            "Epoch 458/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.2345\n",
            "Epoch 459/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.2326\n",
            "Epoch 460/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.2357\n",
            "Epoch 461/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.2392\n",
            "Epoch 462/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.2436\n",
            "Epoch 463/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.2386\n",
            "Epoch 464/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.2355\n",
            "Epoch 465/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.2366\n",
            "Epoch 466/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.2356\n",
            "Epoch 467/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.2439\n",
            "Epoch 468/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.2433\n",
            "Epoch 469/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.2426\n",
            "Epoch 470/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.2454\n",
            "Epoch 471/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.2435\n",
            "Epoch 472/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.2457\n",
            "Epoch 473/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.2544\n",
            "Epoch 474/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.2595\n",
            "Epoch 475/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.2504\n",
            "Epoch 476/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.2440\n",
            "Epoch 477/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.2487\n",
            "Epoch 478/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.2471\n",
            "Epoch 479/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.2525\n",
            "Epoch 480/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.2518\n",
            "Epoch 481/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.2553\n",
            "Epoch 482/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.2542\n",
            "Epoch 483/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.2579\n",
            "Epoch 484/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.2577\n",
            "Epoch 485/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.2553\n",
            "Epoch 486/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.2579\n",
            "Epoch 487/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.2617\n",
            "Epoch 488/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.2628\n",
            "Epoch 489/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.2616\n",
            "Epoch 490/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.2602\n",
            "Epoch 491/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.2663\n",
            "Epoch 492/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.2688\n",
            "Epoch 493/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.2711\n",
            "Epoch 494/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.2718\n",
            "Epoch 495/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.2697\n",
            "Epoch 496/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.2708\n",
            "Epoch 497/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.2704\n",
            "Epoch 498/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.2741\n",
            "Epoch 499/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.2770\n",
            "Epoch 500/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.2689\n",
            "Epoch 501/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.2712\n",
            "Epoch 502/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.2672\n",
            "Epoch 503/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.2694\n",
            "Epoch 504/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.2751\n",
            "Epoch 505/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.2716\n",
            "Epoch 506/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.2755\n",
            "Epoch 507/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.2791\n",
            "Epoch 508/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.2753\n",
            "Epoch 509/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.2791\n",
            "Epoch 510/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.2804\n",
            "Epoch 511/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.2827\n",
            "Epoch 512/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.2834\n",
            "Epoch 513/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.2846\n",
            "Epoch 514/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.2820\n",
            "Epoch 515/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.2732\n",
            "Epoch 516/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.2731\n",
            "Epoch 517/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.2863\n",
            "Epoch 518/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.2871\n",
            "Epoch 519/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.2890\n",
            "Epoch 520/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.2892\n",
            "Epoch 521/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.2941\n",
            "Epoch 522/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2885\n",
            "Epoch 523/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.2885\n",
            "Epoch 524/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.2906\n",
            "Epoch 525/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.2909\n",
            "Epoch 526/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.2916\n",
            "Epoch 527/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.2996\n",
            "Epoch 528/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.2956\n",
            "Epoch 529/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.2939\n",
            "Epoch 530/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.2947\n",
            "Epoch 531/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.2974\n",
            "Epoch 532/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.3023\n",
            "Epoch 533/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.3073\n",
            "Epoch 534/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.2920\n",
            "Epoch 535/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.2881\n",
            "Epoch 536/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.2978\n",
            "Epoch 537/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.3038\n",
            "Epoch 538/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.3103\n",
            "Epoch 539/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.3147\n",
            "Epoch 540/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.3146\n",
            "Epoch 541/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.3124\n",
            "Epoch 542/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.3143\n",
            "Epoch 543/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.3022\n",
            "Epoch 544/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.2998\n",
            "Epoch 545/600\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.3034\n",
            "Epoch 546/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.3032\n",
            "Epoch 547/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.3029\n",
            "Epoch 548/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.3075\n",
            "Epoch 549/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.3092\n",
            "Epoch 550/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.3091\n",
            "Epoch 551/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.3156\n",
            "Epoch 552/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.3126\n",
            "Epoch 553/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.3204\n",
            "Epoch 554/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.3120\n",
            "Epoch 555/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.3190\n",
            "Epoch 556/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.3166\n",
            "Epoch 557/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.3060\n",
            "Epoch 558/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.3098\n",
            "Epoch 559/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.3167\n",
            "Epoch 560/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.3217\n",
            "Epoch 561/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.3221\n",
            "Epoch 562/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.3346\n",
            "Epoch 563/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.3315\n",
            "Epoch 564/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.3312\n",
            "Epoch 565/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.3304\n",
            "Epoch 566/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.3293\n",
            "Epoch 567/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.3225\n",
            "Epoch 568/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.3291\n",
            "Epoch 569/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.3358\n",
            "Epoch 570/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.3400\n",
            "Epoch 571/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.3379\n",
            "Epoch 572/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.3443\n",
            "Epoch 573/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.3412\n",
            "Epoch 574/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.3407\n",
            "Epoch 575/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.3452\n",
            "Epoch 576/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.3461\n",
            "Epoch 577/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.3443\n",
            "Epoch 578/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.3496\n",
            "Epoch 579/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.3537\n",
            "Epoch 580/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.3566\n",
            "Epoch 581/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.3499\n",
            "Epoch 582/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.3495\n",
            "Epoch 583/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.3415\n",
            "Epoch 584/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.3588\n",
            "Epoch 585/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.3466\n",
            "Epoch 586/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.3500\n",
            "Epoch 587/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.3485\n",
            "Epoch 588/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.3536\n",
            "Epoch 589/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.3570\n",
            "Epoch 590/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.3574\n",
            "Epoch 591/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.3575\n",
            "Epoch 592/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.3541\n",
            "Epoch 593/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.3562\n",
            "Epoch 594/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.3641\n",
            "Epoch 595/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.3614\n",
            "Epoch 596/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.3614\n",
            "Epoch 597/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.3654\n",
            "Epoch 598/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.3667\n",
            "Epoch 599/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.3688\n",
            "Epoch 600/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.3662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56f68f8da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOgaHt4qpJa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI3T566SquOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a1411777-c54e-4439-ba81-5ea293f30459"
      },
      "source": [
        "plt.plot(losses)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f56f3156f28>,\n",
              " <matplotlib.lines.Line2D at 0x7f56f3168080>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5_2IgJVIdxL",
        "colab_type": "text"
      },
      "source": [
        "Model is overfitting, adding early stopping and drop out features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SWcOHkOqvbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "#Binary classification so use sigmoid fn and binary_crossentropy\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-84agpKHsxJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5agIIyss2cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, patience=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gra1jIGYtpxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb8fe293-59de-4a11-9c30-4ea3de379f7f"
      },
      "source": [
        "model.fit(x = X_train, y = y_train, epochs = 600, validation_data=(X_test, y_test),\n",
        "          callbacks = [early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.6991 - val_loss: 0.6820\n",
            "Epoch 2/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6560 - val_loss: 0.6447\n",
            "Epoch 3/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.6078\n",
            "Epoch 4/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5786 - val_loss: 0.5706\n",
            "Epoch 5/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5369 - val_loss: 0.5296\n",
            "Epoch 6/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4948 - val_loss: 0.4866\n",
            "Epoch 7/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4494 - val_loss: 0.4456\n",
            "Epoch 8/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4098 - val_loss: 0.4062\n",
            "Epoch 9/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3725 - val_loss: 0.3705\n",
            "Epoch 10/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3376 - val_loss: 0.3404\n",
            "Epoch 11/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3074 - val_loss: 0.3124\n",
            "Epoch 12/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2820 - val_loss: 0.2891\n",
            "Epoch 13/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2596 - val_loss: 0.2673\n",
            "Epoch 14/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2382 - val_loss: 0.2498\n",
            "Epoch 15/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2209 - val_loss: 0.2345\n",
            "Epoch 16/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2058 - val_loss: 0.2226\n",
            "Epoch 17/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1921 - val_loss: 0.2120\n",
            "Epoch 18/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1824 - val_loss: 0.2027\n",
            "Epoch 19/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1734 - val_loss: 0.1956\n",
            "Epoch 20/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1612 - val_loss: 0.1884\n",
            "Epoch 21/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1859\n",
            "Epoch 22/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1773\n",
            "Epoch 23/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1413 - val_loss: 0.1749\n",
            "Epoch 24/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.1687\n",
            "Epoch 25/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1257 - val_loss: 0.1651\n",
            "Epoch 26/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1202 - val_loss: 0.1612\n",
            "Epoch 27/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1150 - val_loss: 0.1588\n",
            "Epoch 28/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.1548\n",
            "Epoch 29/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1055 - val_loss: 0.1516\n",
            "Epoch 30/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1038 - val_loss: 0.1489\n",
            "Epoch 31/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0987 - val_loss: 0.1469\n",
            "Epoch 32/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1442\n",
            "Epoch 33/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.1420\n",
            "Epoch 34/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0880 - val_loss: 0.1402\n",
            "Epoch 35/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.1408\n",
            "Epoch 36/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.1376\n",
            "Epoch 37/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.1372\n",
            "Epoch 38/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0775 - val_loss: 0.1370\n",
            "Epoch 39/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.1338\n",
            "Epoch 40/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.1337\n",
            "Epoch 41/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.1326\n",
            "Epoch 42/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.1322\n",
            "Epoch 43/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.1315\n",
            "Epoch 44/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.1318\n",
            "Epoch 45/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.1315\n",
            "Epoch 46/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.1306\n",
            "Epoch 47/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.1292\n",
            "Epoch 48/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.1292\n",
            "Epoch 49/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.1289\n",
            "Epoch 50/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.1291\n",
            "Epoch 51/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.1291\n",
            "Epoch 52/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.1288\n",
            "Epoch 53/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.1268\n",
            "Epoch 54/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.1341\n",
            "Epoch 55/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.1263\n",
            "Epoch 56/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.1270\n",
            "Epoch 57/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.1259\n",
            "Epoch 58/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.1263\n",
            "Epoch 59/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.1270\n",
            "Epoch 60/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.1267\n",
            "Epoch 61/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.1258\n",
            "Epoch 62/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.1274\n",
            "Epoch 63/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.1263\n",
            "Epoch 64/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.1268\n",
            "Epoch 65/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.1266\n",
            "Epoch 66/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.1271\n",
            "Epoch 67/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.1261\n",
            "Epoch 68/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.1257\n",
            "Epoch 69/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.1287\n",
            "Epoch 70/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.1259\n",
            "Epoch 71/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.1284\n",
            "Epoch 72/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.1264\n",
            "Epoch 73/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.1273\n",
            "Epoch 74/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.1270\n",
            "Epoch 75/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.1292\n",
            "Epoch 76/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.1276\n",
            "Epoch 77/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.1270\n",
            "Epoch 78/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.1273\n",
            "Epoch 79/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.1304\n",
            "Epoch 80/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.1284\n",
            "Epoch 81/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.1327\n",
            "Epoch 82/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.1285\n",
            "Epoch 83/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.1303\n",
            "Epoch 84/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.1327\n",
            "Epoch 85/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.1299\n",
            "Epoch 86/600\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.1354\n",
            "Epoch 87/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.1297\n",
            "Epoch 88/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.1428\n",
            "Epoch 89/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.1307\n",
            "Epoch 90/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.1313\n",
            "Epoch 91/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.1322\n",
            "Epoch 92/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.1317\n",
            "Epoch 93/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.1334\n",
            "Epoch 00093: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc95a2046d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpaGgqnAt4zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8AEM2hyuF-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "db19959c-8698-4065-d39d-21872053978e"
      },
      "source": [
        "plt.plot(model_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc95687c9b0>,\n",
              " <matplotlib.lines.Line2D at 0x7fc95687cac8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXYRbN5NuH4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRkAjzDYuVfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#Binary classification so use sigmoid fn and binary_crossentropy\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhhmvbqtuV8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6760498f-6799-4e06-e739-df358eb32d03"
      },
      "source": [
        "model.fit(x = X_train, y = y_train, epochs = 600, validation_data=(X_test, y_test),\n",
        "          callbacks = [early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.6869 - val_loss: 0.6668\n",
            "Epoch 2/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6601 - val_loss: 0.6517\n",
            "Epoch 3/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6480 - val_loss: 0.6358\n",
            "Epoch 4/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6339 - val_loss: 0.6218\n",
            "Epoch 5/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 0.6047\n",
            "Epoch 6/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 0.5881\n",
            "Epoch 7/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5970 - val_loss: 0.5716\n",
            "Epoch 8/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5888 - val_loss: 0.5532\n",
            "Epoch 9/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5766 - val_loss: 0.5356\n",
            "Epoch 10/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5764 - val_loss: 0.5191\n",
            "Epoch 11/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5316 - val_loss: 0.4977\n",
            "Epoch 12/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5305 - val_loss: 0.4732\n",
            "Epoch 13/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5002 - val_loss: 0.4476\n",
            "Epoch 14/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4823 - val_loss: 0.4206\n",
            "Epoch 15/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4671 - val_loss: 0.3971\n",
            "Epoch 16/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4570 - val_loss: 0.3777\n",
            "Epoch 17/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4181 - val_loss: 0.3560\n",
            "Epoch 18/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4144 - val_loss: 0.3385\n",
            "Epoch 19/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4033 - val_loss: 0.3204\n",
            "Epoch 20/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3752 - val_loss: 0.3023\n",
            "Epoch 21/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3666 - val_loss: 0.2863\n",
            "Epoch 22/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3420 - val_loss: 0.2691\n",
            "Epoch 23/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3527 - val_loss: 0.2591\n",
            "Epoch 24/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3229 - val_loss: 0.2522\n",
            "Epoch 25/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3046 - val_loss: 0.2466\n",
            "Epoch 26/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3238 - val_loss: 0.2431\n",
            "Epoch 27/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2677 - val_loss: 0.2282\n",
            "Epoch 28/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3167 - val_loss: 0.2218\n",
            "Epoch 29/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2667 - val_loss: 0.2136\n",
            "Epoch 30/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2493 - val_loss: 0.2042\n",
            "Epoch 31/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2862 - val_loss: 0.1972\n",
            "Epoch 32/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2623 - val_loss: 0.1947\n",
            "Epoch 33/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2779 - val_loss: 0.1918\n",
            "Epoch 34/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2767 - val_loss: 0.1900\n",
            "Epoch 35/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2247 - val_loss: 0.1840\n",
            "Epoch 36/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2557 - val_loss: 0.1837\n",
            "Epoch 37/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2424 - val_loss: 0.1774\n",
            "Epoch 38/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2234 - val_loss: 0.1716\n",
            "Epoch 39/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2280 - val_loss: 0.1674\n",
            "Epoch 40/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2011 - val_loss: 0.1635\n",
            "Epoch 41/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2256 - val_loss: 0.1667\n",
            "Epoch 42/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2438 - val_loss: 0.1603\n",
            "Epoch 43/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2045 - val_loss: 0.1592\n",
            "Epoch 44/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1868 - val_loss: 0.1614\n",
            "Epoch 45/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2086 - val_loss: 0.1564\n",
            "Epoch 46/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1998 - val_loss: 0.1523\n",
            "Epoch 47/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2041 - val_loss: 0.1500\n",
            "Epoch 48/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1684 - val_loss: 0.1471\n",
            "Epoch 49/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.1467\n",
            "Epoch 50/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1832 - val_loss: 0.1450\n",
            "Epoch 51/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2033 - val_loss: 0.1470\n",
            "Epoch 52/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1730 - val_loss: 0.1452\n",
            "Epoch 53/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1758 - val_loss: 0.1435\n",
            "Epoch 54/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1612 - val_loss: 0.1383\n",
            "Epoch 55/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1613 - val_loss: 0.1467\n",
            "Epoch 56/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1657 - val_loss: 0.1391\n",
            "Epoch 57/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1452 - val_loss: 0.1336\n",
            "Epoch 58/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1520 - val_loss: 0.1322\n",
            "Epoch 59/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1439 - val_loss: 0.1299\n",
            "Epoch 60/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1660 - val_loss: 0.1306\n",
            "Epoch 61/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1633 - val_loss: 0.1311\n",
            "Epoch 62/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1578 - val_loss: 0.1301\n",
            "Epoch 63/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1484 - val_loss: 0.1297\n",
            "Epoch 64/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1355 - val_loss: 0.1274\n",
            "Epoch 65/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1522 - val_loss: 0.1269\n",
            "Epoch 66/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1305 - val_loss: 0.1246\n",
            "Epoch 67/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1284 - val_loss: 0.1250\n",
            "Epoch 68/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1464 - val_loss: 0.1280\n",
            "Epoch 69/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1279 - val_loss: 0.1231\n",
            "Epoch 70/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1267 - val_loss: 0.1246\n",
            "Epoch 71/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1169 - val_loss: 0.1213\n",
            "Epoch 72/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1196\n",
            "Epoch 73/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1585 - val_loss: 0.1199\n",
            "Epoch 74/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1279 - val_loss: 0.1195\n",
            "Epoch 75/600\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1284 - val_loss: 0.1214\n",
            "Epoch 76/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1179\n",
            "Epoch 77/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 0.1200\n",
            "Epoch 78/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1437 - val_loss: 0.1167\n",
            "Epoch 79/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1222 - val_loss: 0.1185\n",
            "Epoch 80/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.1187\n",
            "Epoch 81/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0989 - val_loss: 0.1199\n",
            "Epoch 82/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1381 - val_loss: 0.1250\n",
            "Epoch 83/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1038 - val_loss: 0.1199\n",
            "Epoch 84/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.1193\n",
            "Epoch 85/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1322 - val_loss: 0.1216\n",
            "Epoch 86/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.1220\n",
            "Epoch 87/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1086 - val_loss: 0.1172\n",
            "Epoch 88/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0910 - val_loss: 0.1163\n",
            "Epoch 89/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1132\n",
            "Epoch 90/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.1138\n",
            "Epoch 91/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 0.1176\n",
            "Epoch 92/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1273 - val_loss: 0.1156\n",
            "Epoch 93/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1034 - val_loss: 0.1118\n",
            "Epoch 94/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0990 - val_loss: 0.1127\n",
            "Epoch 95/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1206 - val_loss: 0.1158\n",
            "Epoch 96/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1043 - val_loss: 0.1140\n",
            "Epoch 97/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0908 - val_loss: 0.1114\n",
            "Epoch 98/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.1145\n",
            "Epoch 99/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1084 - val_loss: 0.1106\n",
            "Epoch 100/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.1177\n",
            "Epoch 101/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.1145\n",
            "Epoch 102/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1123 - val_loss: 0.1225\n",
            "Epoch 103/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0908 - val_loss: 0.1251\n",
            "Epoch 104/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.1101\n",
            "Epoch 105/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1080 - val_loss: 0.1176\n",
            "Epoch 106/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.1220\n",
            "Epoch 107/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1024 - val_loss: 0.1136\n",
            "Epoch 108/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1040 - val_loss: 0.1126\n",
            "Epoch 109/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.1150\n",
            "Epoch 110/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.1115\n",
            "Epoch 111/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.1251\n",
            "Epoch 112/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0994 - val_loss: 0.1169\n",
            "Epoch 113/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0948 - val_loss: 0.1210\n",
            "Epoch 114/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0982 - val_loss: 0.1130\n",
            "Epoch 115/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.1188\n",
            "Epoch 116/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.1149\n",
            "Epoch 117/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.1117\n",
            "Epoch 118/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1017 - val_loss: 0.1283\n",
            "Epoch 119/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.1099\n",
            "Epoch 120/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0941 - val_loss: 0.1112\n",
            "Epoch 121/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.1159\n",
            "Epoch 122/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0930 - val_loss: 0.1179\n",
            "Epoch 123/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0924 - val_loss: 0.1146\n",
            "Epoch 124/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.1152\n",
            "Epoch 125/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1000 - val_loss: 0.1189\n",
            "Epoch 126/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.1138\n",
            "Epoch 127/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.1145\n",
            "Epoch 128/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0794 - val_loss: 0.1182\n",
            "Epoch 129/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.1142\n",
            "Epoch 130/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.1188\n",
            "Epoch 131/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.1175\n",
            "Epoch 132/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.1247\n",
            "Epoch 133/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.1167\n",
            "Epoch 134/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0953 - val_loss: 0.1141\n",
            "Epoch 135/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.1200\n",
            "Epoch 136/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.1165\n",
            "Epoch 137/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.1196\n",
            "Epoch 138/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0943 - val_loss: 0.1114\n",
            "Epoch 139/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.1151\n",
            "Epoch 140/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.1156\n",
            "Epoch 141/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.1095\n",
            "Epoch 142/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0934 - val_loss: 0.1136\n",
            "Epoch 143/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.1177\n",
            "Epoch 144/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.1180\n",
            "Epoch 145/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0723 - val_loss: 0.1105\n",
            "Epoch 146/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.1095\n",
            "Epoch 147/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0719 - val_loss: 0.1117\n",
            "Epoch 148/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.1107\n",
            "Epoch 149/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.1139\n",
            "Epoch 150/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.1127\n",
            "Epoch 151/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.1135\n",
            "Epoch 152/600\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.1134\n",
            "Epoch 153/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0967 - val_loss: 0.1184\n",
            "Epoch 154/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.1276\n",
            "Epoch 155/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.1121\n",
            "Epoch 156/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.1214\n",
            "Epoch 157/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.1204\n",
            "Epoch 158/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.1152\n",
            "Epoch 159/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.1137\n",
            "Epoch 160/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.1197\n",
            "Epoch 161/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.1128\n",
            "Epoch 162/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.1133\n",
            "Epoch 163/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.1221\n",
            "Epoch 164/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.1141\n",
            "Epoch 165/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0790 - val_loss: 0.1120\n",
            "Epoch 166/600\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.1232\n",
            "Epoch 00166: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc958088c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErrRMGeIuwlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spQ752ETu5mw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "66faaefe-6d68-4028-82d9-3497faeb91c3"
      },
      "source": [
        "plt.plot(model_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc95688a438>,\n",
              " <matplotlib.lines.Line2D at 0x7fc95aa35940>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAQ2leywu6_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AsA52czvJb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NxnNLbwvU-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c0346bd9-5b24-4396-87b3-e474faa241b7"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        66\n",
            "           1       0.98      0.98      0.98       105\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.98      0.98      0.98       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3afKVXzfvXLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "14b1f47d-b06a-461a-d592-850dab78726e"
      },
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 64   2]\n",
            " [  2 103]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_-Pz3M0vaNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}